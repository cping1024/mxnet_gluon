{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-28T06:56:55.886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/allen/.mxnet/datasets/fashion-mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-images-idx3-ubyte.gz...\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from mxnet import gluon\n",
    "from mxnet import ndarray as nd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def transform(data, label):\n",
    "    return data.astype('float32')/255, label.astype('float32')\n",
    "\n",
    "mnist_train = gluon.data.vision.FashionMNIST(train=True, transform=transform)\n",
    "mnist_test = gluon.data.vision.FashionMNIST(train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-28T06:58:18.732Z"
    }
   },
   "outputs": [],
   "source": [
    "data, label = mnist_train[0]\n",
    "('example shape:', data.shape, 'label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-28T06:58:20.522Z"
    }
   },
   "outputs": [],
   "source": [
    "# show example data\n",
    "def show_images(images):\n",
    "    n = images.shape[0]\n",
    "    _, figs = plt.subplots(1, 0, figsize = (15, 15))\n",
    "    for i in range(n):\n",
    "        figs[i].imshow(images[i].reshape((28, 28)).asnumpy())\n",
    "        figs[i].axes.get_xaxis().set_visible(False)\n",
    "        figs[i].axes.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "def get_text_labels(label):\n",
    "    text_lables = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'short', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in label]\n",
    "\n",
    "data, label = mnist_train[0:9]\n",
    "show_images(data)\n",
    "print(get_text_labels(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-28T06:58:22.292Z"
    }
   },
   "outputs": [],
   "source": [
    "# read train data\n",
    "batch_size = 256\n",
    "train_data = gluon.data.DataLoader(mnist_train, batch_size, shuffle = True)\n",
    "test_data = gluon.data.DataLoader(mnist_test, batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-28T06:58:23.042Z"
    }
   },
   "outputs": [],
   "source": [
    "# init model params\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "W = nd.random_normal(shape = (num_inputs, num_outputs))\n",
    "b = nd.random_normal(shape = (num_outputs))\n",
    "params = [W, b]\n",
    "\n",
    "# attach grad\n",
    "for param in params:\n",
    "    param.attach_grad()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-28T06:58:23.722Z"
    }
   },
   "outputs": [],
   "source": [
    "# define softmax function\n",
    "def softmax(X):\n",
    "    exp = nd.exp(X)\n",
    "    part = exp.sum(axis = 1, keepdims = True)\n",
    "    return exp / part\n",
    "\n",
    "X = nd.random_normal(shape = (2, 5))\n",
    "X_prob = softmax(X)\n",
    "print X_prob\n",
    "print X_prob.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-28T06:58:24.770Z"
    }
   },
   "outputs": [],
   "source": [
    "# define cross_entropy function\n",
    "def cross_entropy(yhat, y):\n",
    "    return -nd.pick(nd.log(yhat), y)\n",
    "\n",
    "# define accuracy function\n",
    "def accuracy(output, label):\n",
    "    return nd.mean(output.argmax(axis = 1) == label).asscalar()\n",
    "\n",
    "# define calc accuracy\n",
    "def evaluate_accuracy(data_iterator, net):\n",
    "    acc = 0.\n",
    "    for data, label in data_iterator:\n",
    "        output = net(data)\n",
    "        acc += accuracy(output, label)\n",
    "        \n",
    "    return acc / len(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T06:56:30.761248Z",
     "start_time": "2018-03-28T06:56:30.733537Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-078e7a7a2872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mauto_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# train logistic regression model\n",
    "\n",
    "# define SGD function\n",
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "learning_rate = 0.1\n",
    "for expoch in range(5):\n",
    "    train_loss = 0.\n",
    "    train_acc = 0.\n",
    "    for data, label in train_data:\n",
    "        with auto_grad.record():\n",
    "            output = net(data)\n",
    "            loss = cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        SDG(params, learning_rate / batch_size)\n",
    "        \n",
    "        train_loss += nd.mean(loss).asscalar()\n",
    "        train_acc += accuracy(output, label)\n",
    "        \n",
    "    test_acc = evaluate_accuracy(test_data, net)\n",
    "    print(\"Epoch %d. Loss: %f, Train acc %f, Test acc %f\" % (epoch, train_loss / len(train_data), train_acc / len(train_data), test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
